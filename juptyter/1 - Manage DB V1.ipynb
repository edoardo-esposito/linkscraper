{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import nltk\n",
    "import re\n",
    "import csv\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "pd.set_option('display.max_colwidth', 300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-27LekL_lqVR"
   },
   "source": [
    "## Load and clean data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta = pd.read_excel(\"../DB Articoli V8.xlsx\")\n",
    "meta = meta.replace(np.nan, '', regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Titolo</th>\n",
       "      <th>Url</th>\n",
       "      <th>Data</th>\n",
       "      <th>Testo</th>\n",
       "      <th>Fonte</th>\n",
       "      <th>Trend 1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>52360f85d1245da83f1da41ebc3e8449</td>\n",
       "      <td>Numenta Is Imitating Your Brain</td>\n",
       "      <td>https://singularityhub.com/2008/07/11/numenta-is-imitating-your-brain/</td>\n",
       "      <td>2008-07-11</td>\n",
       "      <td>Decent piece in BusinessWeek profiling Jeff Hawkins startup Numenta. Numenta is building artificial intelligence that attempts to replicate the function of the human neocortex to solve hard problems. The software specializes in recognizing patterns within massive streams of data. I am a big fan ...</td>\n",
       "      <td>SingularityHub</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 ID                           Titolo  \\\n",
       "0  52360f85d1245da83f1da41ebc3e8449  Numenta Is Imitating Your Brain   \n",
       "\n",
       "                                                                      Url  \\\n",
       "0  https://singularityhub.com/2008/07/11/numenta-is-imitating-your-brain/   \n",
       "\n",
       "        Data  \\\n",
       "0 2008-07-11   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                         Testo  \\\n",
       "0  Decent piece in BusinessWeek profiling Jeff Hawkins startup Numenta. Numenta is building artificial intelligence that attempts to replicate the function of the human neocortex to solve hard problems. The software specializes in recognizing patterns within massive streams of data. I am a big fan ...   \n",
       "\n",
       "            Fonte Trend 1  \n",
       "0  SingularityHub          "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#meta.rename(columns={\n",
    "#    'published': \"Data\",\n",
    "#    'title': 'Titolo',\n",
    "#    'summary': 'Testo'\n",
    "#}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta['Data'] = pd.to_datetime(meta['Data'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hashlib\n",
    "\n",
    "def generate_link_id(titolo):\n",
    "    link_id = hashlib.md5(titolo.encode('utf-8')).hexdigest()\n",
    "    return link_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\edoardo.esposito\\AppData\\Local\\Continuum\\anaconda3\\envs\\techadv\\lib\\site-packages\\ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "#articoli = meta[['ID','Titolo', 'Data', 'Testo']]\n",
    "articoli = meta[['Titolo', 'Data', 'Testo']]\n",
    "articoli['ID'] = articoli['Titolo'].apply(lambda x: generate_link_id(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Titolo</th>\n",
       "      <th>Data</th>\n",
       "      <th>Testo</th>\n",
       "      <th>ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Numenta Is Imitating Your Brain</td>\n",
       "      <td>2008-07-11</td>\n",
       "      <td>Decent piece in BusinessWeek profiling Jeff Hawkins startup Numenta. Numenta is building artificial intelligence that attempts to replicate the function of the human neocortex to solve hard problems. The software specializes in recognizing patterns within massive streams of data. I am a big fan ...</td>\n",
       "      <td>52360f85d1245da83f1da41ebc3e8449</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            Titolo       Data  \\\n",
       "0  Numenta Is Imitating Your Brain 2008-07-11   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                         Testo  \\\n",
       "0  Decent piece in BusinessWeek profiling Jeff Hawkins startup Numenta. Numenta is building artificial intelligence that attempts to replicate the function of the human neocortex to solve hard problems. The software specializes in recognizing patterns within massive streams of data. I am a big fan ...   \n",
       "\n",
       "                                 ID  \n",
       "0  52360f85d1245da83f1da41ebc3e8449  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "articoli.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numero totale di articoli: 10703\n"
     ]
    }
   ],
   "source": [
    "print (\"Numero totale di articoli: %d\" % len(articoli['ID']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-27LekL_lqVR"
   },
   "source": [
    "## Insert Trends"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trend1 = []\n",
    "for i in meta['Trend 1']:\n",
    "    trend1.append(i)\n",
    "\n",
    "Trend = []\n",
    "for i in range(len(article_id)):\n",
    "    l = []\n",
    "    if len(trend1[i]): l.append(trend1[i])\n",
    "\n",
    "    Trend.append(', '.join(map(str, list(l)))) \n",
    "    \n",
    "Trend[0]## Remove stopwords from data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Tech Dataframe\n",
    "trend = pd.DataFrame({'ID': article_id, 'Trend': Trend})\n",
    "trend.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "articoli = pd.merge(articoli, trend, on = 'ID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove samples with no tags\n",
    "articoli['Trend'] = articoli['Trend'].apply(lambda y: '' if len(y)==0 else y)\n",
    "articoli = articoli[~(articoli['Trend'].str.len() == 0)]\n",
    "articoli = articoli[~(articoli['Testo'].str.len() == 0)]\n",
    "articoli = articoli.dropna(subset=['Data'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(articoli)\n",
    "print (\"Numero totale di articoli: %d\" % len(articoli))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-27LekL_lqVR"
   },
   "source": [
    "## Clean Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for text cleaning \n",
    "def clean_text(text):\n",
    "    # remove backslash-apostrophe \n",
    "    text = re.sub(\"\\'\", \"\", text)\n",
    "    text = re.sub(r'[?|!|\\'|\"|#]',r'',text)\n",
    "    text = re.sub(r'[.|,|)|(|\\|/]',r' ',text)\n",
    "    # remove everything except alphabets \n",
    "    text = re.sub(\"[^a-zA-Z]\",\" \",text) \n",
    "    \n",
    "    text = text.replace(\"\\n\",\" \")\n",
    "    \n",
    "    # remove whitespaces \n",
    "    text = ' '.join(text.split()) \n",
    "    # convert text to lowercase \n",
    "    text = text.lower() \n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\edoardo.esposito\\AppData\\Local\\Continuum\\anaconda3\\envs\\techadv\\lib\\site-packages\\ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "C:\\Users\\edoardo.esposito\\AppData\\Local\\Continuum\\anaconda3\\envs\\techadv\\lib\\site-packages\\ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "articoli['Clean_Titolo'] = articoli['Titolo'].apply(lambda x: clean_text(x))\n",
    "articoli['Clean_Testo'] = articoli['Testo'].apply(lambda x: clean_text(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numero totale di articoli: 10703\n"
     ]
    }
   ],
   "source": [
    "print (\"Numero totale di articoli: %d\" % len(articoli))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Titolo</th>\n",
       "      <th>Data</th>\n",
       "      <th>Testo</th>\n",
       "      <th>ID</th>\n",
       "      <th>Clean_Titolo</th>\n",
       "      <th>Clean_Testo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Numenta Is Imitating Your Brain</td>\n",
       "      <td>2008-07-11</td>\n",
       "      <td>Decent piece in BusinessWeek profiling Jeff Hawkins startup Numenta. Numenta is building artificial intelligence that attempts to replicate the function of the human neocortex to solve hard problems. The software specializes in recognizing patterns within massive streams of data. I am a big fan ...</td>\n",
       "      <td>52360f85d1245da83f1da41ebc3e8449</td>\n",
       "      <td>numenta is imitating your brain</td>\n",
       "      <td>decent piece in businessweek profiling jeff hawkins startup numenta numenta is building artificial intelligence that attempts to replicate the function of the human neocortex to solve hard problems the software specializes in recognizing patterns within massive streams of data i am a big fan of ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            Titolo       Data  \\\n",
       "0  Numenta Is Imitating Your Brain 2008-07-11   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                         Testo  \\\n",
       "0  Decent piece in BusinessWeek profiling Jeff Hawkins startup Numenta. Numenta is building artificial intelligence that attempts to replicate the function of the human neocortex to solve hard problems. The software specializes in recognizing patterns within massive streams of data. I am a big fan ...   \n",
       "\n",
       "                                 ID                     Clean_Titolo  \\\n",
       "0  52360f85d1245da83f1da41ebc3e8449  numenta is imitating your brain   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                   Clean_Testo  \n",
       "0  decent piece in businessweek profiling jeff hawkins startup numenta numenta is building artificial intelligence that attempts to replicate the function of the human neocortex to solve hard problems the software specializes in recognizing patterns within massive streams of data i am a big fan of ...  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "articoli.head(1)\n",
    "#articoli.sample(5, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-27LekL_lqVR"
   },
   "source": [
    "## Remove stopwords from data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "\n",
    "stop_words = nltk.corpus.stopwords.words('english')\n",
    "my_stopwords = ['also','said', 'one', 'may', 'polls', 'sorry', 'like', 'use', 'many', 'make', 'could', \n",
    "                'even', 'says', 'new', 'us', 'would', 'time', 'companies', 'moment', 'way', 'using', 'two',\n",
    "               'across', 'well', 'world', 'first', 'system', 'million', 'systems', 'including', 'example', 'year', \n",
    "                'based', 'googletagcmdpushfunction', 'th']\n",
    "stop_words.extend(my_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to remove stopwords\n",
    "def remove_stopwords(text):\n",
    "    no_stopword_text = [w for w in text.split() if not w in stop_words]\n",
    "    return ' '.join(no_stopword_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\edoardo.esposito\\AppData\\Local\\Continuum\\anaconda3\\envs\\techadv\\lib\\site-packages\\ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "C:\\Users\\edoardo.esposito\\AppData\\Local\\Continuum\\anaconda3\\envs\\techadv\\lib\\site-packages\\ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "articoli['Clean_Titolo'] = articoli['Clean_Titolo'].apply(lambda x: remove_stopwords(x))\n",
    "articoli['Clean_Testo'] = articoli['Clean_Testo'].apply(lambda x: remove_stopwords(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "articoli['Txt'] = articoli['Clean_Titolo'] + \" \" + articoli['Clean_Testo']\n",
    "del(articoli['Clean_Titolo'])\n",
    "del(articoli['Clean_Testo'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-27LekL_lqVR"
   },
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_date(df,column):\n",
    "    df[\"Anno\"] = df[column].apply(lambda x: x.year)\n",
    "    df[\"Mese\"] = df[column].apply(lambda x: x.month)\n",
    "    df[\"Day\"] = df[column].apply(lambda x: x.day)\n",
    "    \n",
    "extract_date(articoli, \"Data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_week_number(df, column):\n",
    "    df[\"Week\"] = df[column].apply(lambda x: datetime.date(int(x.year), int(x.month), int(x.day)).strftime(\"%V\"))\n",
    "    #datetime.date(articoli['Data'][0].year, articoli['Data'][0].month , articoli['Data'][0].day).strftime(\"%V\")\n",
    "    \n",
    "extract_week_number(articoli, \"Data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Titolo</th>\n",
       "      <th>Data</th>\n",
       "      <th>Testo</th>\n",
       "      <th>ID</th>\n",
       "      <th>Txt</th>\n",
       "      <th>Anno</th>\n",
       "      <th>Mese</th>\n",
       "      <th>Day</th>\n",
       "      <th>Week</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Numenta Is Imitating Your Brain</td>\n",
       "      <td>2008-07-11</td>\n",
       "      <td>Decent piece in BusinessWeek profiling Jeff Hawkins startup Numenta. Numenta is building artificial intelligence that attempts to replicate the function of the human neocortex to solve hard problems. The software specializes in recognizing patterns within massive streams of data. I am a big fan ...</td>\n",
       "      <td>52360f85d1245da83f1da41ebc3e8449</td>\n",
       "      <td>numenta imitating brain decent piece businessweek profiling jeff hawkins startup numenta numenta building artificial intelligence attempts replicate function human neocortex solve hard problems software specializes recognizing patterns within massive streams data big fan jeff hawkins short plug ...</td>\n",
       "      <td>2008</td>\n",
       "      <td>7</td>\n",
       "      <td>11</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            Titolo       Data  \\\n",
       "0  Numenta Is Imitating Your Brain 2008-07-11   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                         Testo  \\\n",
       "0  Decent piece in BusinessWeek profiling Jeff Hawkins startup Numenta. Numenta is building artificial intelligence that attempts to replicate the function of the human neocortex to solve hard problems. The software specializes in recognizing patterns within massive streams of data. I am a big fan ...   \n",
       "\n",
       "                                 ID  \\\n",
       "0  52360f85d1245da83f1da41ebc3e8449   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                           Txt  \\\n",
       "0  numenta imitating brain decent piece businessweek profiling jeff hawkins startup numenta numenta building artificial intelligence attempts replicate function human neocortex solve hard problems software specializes recognizing patterns within massive streams data big fan jeff hawkins short plug ...   \n",
       "\n",
       "   Anno  Mese  Day Week  \n",
       "0  2008     7   11   28  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "articoli.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-27LekL_lqVR"
   },
   "source": [
    "## Extract keywords for each row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import re\n",
    "## Remove stopwords from data\n",
    "corpus = articoli['Txt']\n",
    "cv=CountVectorizer(max_df=0.8,stop_words=stop_words, max_features=10000, ngram_range=(1,3))\n",
    "X=cv.fit_transform(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://medium.com/analytics-vidhya/automated-keyword-extraction-from-articles-using-nlp-bfd864f41b34\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    " \n",
    "tfidf_transformer=TfidfTransformer(smooth_idf=True,use_idf=True)\n",
    "tfidf_transformer.fit(X)\n",
    "\n",
    "# get feature names\n",
    "feature_names=cv.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function for sorting tf_idf in descending order\n",
    "from scipy.sparse import coo_matrix\n",
    "def sort_coo(coo_matrix):\n",
    "    tuples = zip(coo_matrix.col, coo_matrix.data)\n",
    "    return sorted(tuples, key=lambda x: (x[1], x[0]), reverse=True)\n",
    " \n",
    "def extract_topn_from_vector(feature_names, sorted_items, topn=10):\n",
    "    \"\"\"get the feature names and tf-idf score of top n items\"\"\"\n",
    "    \n",
    "    #use only topn items from vector\n",
    "    sorted_items = sorted_items[:topn]\n",
    " \n",
    "    score_vals = []\n",
    "    feature_vals = []\n",
    "    \n",
    "    # word index and corresponding tf-idf score\n",
    "    for idx, score in sorted_items:\n",
    "        \n",
    "        #keep track of feature name and its corresponding score\n",
    "        score_vals.append(round(score, 3))\n",
    "        feature_vals.append(feature_names[idx])\n",
    " \n",
    "    #create a tuples of feature,score\n",
    "    #results = zip(feature_vals,score_vals)\n",
    "    results= {}\n",
    "    for idx in range(len(feature_vals)):\n",
    "        results[feature_vals[idx]]=score_vals[idx]\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_keys_for_row(doc, n):  \n",
    "    #generate tf-idf for the given document\n",
    "    tf_idf_vector=tfidf_transformer.transform(cv.transform([doc]))\n",
    "\n",
    "    #sort the tf-idf vectors by descending order of scores\n",
    "    sorted_items=sort_coo(tf_idf_vector.tocoo())\n",
    "    \n",
    "    #extract only the top n\n",
    "    keywords=extract_topn_from_vector(feature_names,sorted_items, n)\n",
    "    \n",
    "    kw = []\n",
    "    for k in keywords:\n",
    "        kw.append(k)\n",
    "\n",
    "    kw2 = []\n",
    "    for k in kw:\n",
    "        if len(k.split()) == 2:\n",
    "            kw2.append (k.split()[0].strip())\n",
    "            kw2.append (k.split()[1].strip())\n",
    "            \n",
    "        if len(k.split()) == 3:\n",
    "            kw2.append (k.split()[0].strip() + ' ' + k.split()[1].strip())\n",
    "            kw2.append (k.split()[1].strip() + ' ' + k.split()[2].strip())\n",
    "            kw2.append (k.split()[0].strip())\n",
    "            kw2.append (k.split()[1].strip())\n",
    "            kw2.append (k.split()[2].strip())\n",
    "            \n",
    "    kw = kw+kw2        \n",
    "        \n",
    "    return \", \".join(kw)\n",
    "        \n",
    "#extract_keys_for_row(articoli['Txt'][1], 25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO man mano che aumentano gli articoli sarà sempre più lungo: vanno estratti in un file separato\n",
    "articoli['Keywords'] = articoli['Txt'].apply(lambda x: extract_keys_for_row(x,25))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Titolo</th>\n",
       "      <th>Data</th>\n",
       "      <th>Testo</th>\n",
       "      <th>ID</th>\n",
       "      <th>Txt</th>\n",
       "      <th>Anno</th>\n",
       "      <th>Mese</th>\n",
       "      <th>Day</th>\n",
       "      <th>Week</th>\n",
       "      <th>Keywords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Numenta Is Imitating Your Brain</td>\n",
       "      <td>2008-07-11</td>\n",
       "      <td>Decent piece in BusinessWeek profiling Jeff Hawkins startup Numenta. Numenta is building artificial intelligence that attempts to replicate the function of the human neocortex to solve hard problems. The software specializes in recognizing patterns within massive streams of data. I am a big fan ...</td>\n",
       "      <td>52360f85d1245da83f1da41ebc3e8449</td>\n",
       "      <td>numenta imitating brain decent piece businessweek profiling jeff hawkins startup numenta numenta building artificial intelligence attempts replicate function human neocortex solve hard problems software specializes recognizing patterns within massive streams data big fan jeff hawkins short plug ...</td>\n",
       "      <td>2008</td>\n",
       "      <td>7</td>\n",
       "      <td>11</td>\n",
       "      <td>28</td>\n",
       "      <td>jeff, brain, palm, decent, intelligence, specializes, tech industry, secrets, straightforward, inner, recognizing, introduction, pursue, replicate, fan, streams, unlock, neuroscience, dream, plug, attempts, book, degree, pilot, piece, tech, industry</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            Titolo       Data  \\\n",
       "0  Numenta Is Imitating Your Brain 2008-07-11   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                         Testo  \\\n",
       "0  Decent piece in BusinessWeek profiling Jeff Hawkins startup Numenta. Numenta is building artificial intelligence that attempts to replicate the function of the human neocortex to solve hard problems. The software specializes in recognizing patterns within massive streams of data. I am a big fan ...   \n",
       "\n",
       "                                 ID  \\\n",
       "0  52360f85d1245da83f1da41ebc3e8449   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                           Txt  \\\n",
       "0  numenta imitating brain decent piece businessweek profiling jeff hawkins startup numenta numenta building artificial intelligence attempts replicate function human neocortex solve hard problems software specializes recognizing patterns within massive streams data big fan jeff hawkins short plug ...   \n",
       "\n",
       "   Anno  Mese  Day Week  \\\n",
       "0  2008     7   11   28   \n",
       "\n",
       "                                                                                                                                                                                                                                                    Keywords  \n",
       "0  jeff, brain, palm, decent, intelligence, specializes, tech industry, secrets, straightforward, inner, recognizing, introduction, pursue, replicate, fan, streams, unlock, neuroscience, dream, plug, attempts, book, degree, pilot, piece, tech, industry  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "articoli.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-27LekL_lqVR"
   },
   "source": [
    "## Apply tags to keywords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "provare a farlo anche sul testo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "tags = pd.read_excel(\"Keywords to Tags V8.xlsx\")\n",
    "tags = tags.replace(np.nan, '', regex=True)\n",
    "del(tags['Tag 1'])\n",
    "del(tags['Tag 2'])\n",
    "del(tags['Tag 3'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "tags = tags[~(tags['Tags'].str.len() == 0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Words</th>\n",
       "      <th>Tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1238</td>\n",
       "      <td>1238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>1225</td>\n",
       "      <td>455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>renewable energy</td>\n",
       "      <td>Tech: AI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>2</td>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Words      Tags\n",
       "count               1238      1238\n",
       "unique              1225       455\n",
       "top     renewable energy  Tech: AI\n",
       "freq                   2        66"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tags.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Keywords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>52360f85d1245da83f1da41ebc3e8449</td>\n",
       "      <td>jeff, brain, palm, decent, intelligence, specializes, tech industry, secrets, straightforward, inner, recognizing, introduction, pursue, replicate, fan, streams, unlock, neuroscience, dream, plug, attempts, book, degree, pilot, piece, tech, industry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>d99a761a52235562022f899b002022a5</td>\n",
       "      <td>brain, synapses, conscious, reverse, engineer, machine, consciousness, strategies, decades, article, whose, koch, microscopy, simulating, foreseeable future, wiring, ieee, foreseeable, strengths, lesson, explicit, electron, titled, complementary, nervous, foreseeable, future</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>f37e326486637f988d4864652e15c2f2</td>\n",
       "      <td>singularity, ieee, report, special, www, highlighting, representing, selection, org, comprehensive, views, diverse, posts, located, spectrum, cool, fields, cover, interested, separate, produced, insights, read, issue, must</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2af2b2d721da8743585f9fd54f2d8aac</td>\n",
       "      <td>stimulation, nerve, laser, nerves, cells, electrical, article, nearby, experiments, membrane, stimulating, caused, limbs, stimulate, desired, human, light, mechanism, tissue, damage, picture, contact, target, physical, hypothesis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>c131e5ae7fbeac377973ba06bea52999</td>\n",
       "      <td>brain, healthy, member, singularity, try, login, screenshot, chart, specially, enough, per day, historical, abilities, index, participate, bodies, amazing, page, shape, get, excited, dedicated, signed, keeping, technological, per, day</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 ID  \\\n",
       "0  52360f85d1245da83f1da41ebc3e8449   \n",
       "1  d99a761a52235562022f899b002022a5   \n",
       "2  f37e326486637f988d4864652e15c2f2   \n",
       "3  2af2b2d721da8743585f9fd54f2d8aac   \n",
       "4  c131e5ae7fbeac377973ba06bea52999   \n",
       "\n",
       "                                                                                                                                                                                                                                                                              Keywords  \n",
       "0                            jeff, brain, palm, decent, intelligence, specializes, tech industry, secrets, straightforward, inner, recognizing, introduction, pursue, replicate, fan, streams, unlock, neuroscience, dream, plug, attempts, book, degree, pilot, piece, tech, industry  \n",
       "1  brain, synapses, conscious, reverse, engineer, machine, consciousness, strategies, decades, article, whose, koch, microscopy, simulating, foreseeable future, wiring, ieee, foreseeable, strengths, lesson, explicit, electron, titled, complementary, nervous, foreseeable, future  \n",
       "2                                                       singularity, ieee, report, special, www, highlighting, representing, selection, org, comprehensive, views, diverse, posts, located, spectrum, cool, fields, cover, interested, separate, produced, insights, read, issue, must  \n",
       "3                                                stimulation, nerve, laser, nerves, cells, electrical, article, nearby, experiments, membrane, stimulating, caused, limbs, stimulate, desired, human, light, mechanism, tissue, damage, picture, contact, target, physical, hypothesis  \n",
       "4                                           brain, healthy, member, singularity, try, login, screenshot, chart, specially, enough, per day, historical, abilities, index, participate, bodies, amazing, page, shape, get, excited, dedicated, signed, keeping, technological, per, day  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keywords = articoli[['ID','Keywords']]\n",
    "keywords.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = pd.concat([pd.Series(row['ID'], row['Keywords'].split(', ')) \n",
    "           for _, row in keywords.iterrows()]).reset_index().rename(columns={\"index\": \"Words\", 0: \"ID\"})\n",
    "words.sort_values(by=['Words'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#words.describe()\n",
    "#words.to_csv('prova.csv', sep=\";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = tags.merge(words, on=\"Words\", how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#res.head()\n",
    "#res.to_csv('prova.csv', sep=\";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = res.groupby('ID').agg(lambda x: x.tolist()).rename({'Tags': 'ComputedTags'}, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Words</th>\n",
       "      <th>ComputedTags</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0000e2070c13ff3dd2b8b8c0f4225f17</th>\n",
       "      <td>[air, air, air quality, cleantech, climate, facebook, facebook, facebook, facebook, facebook, twitter, twitter, twitter]</td>\n",
       "      <td>[Tag: Air, Tag: Air, Tag: Air, Tag: Pollution, Tag: Clean Technology, Tag: Climate Change, Company: Facebook, Vertical: Technology, Company: Facebook, Vertical: Technology, Company: Facebook, Vertical: Technology, Company: Facebook, Vertical: Technology, Company: Facebook, Vertical: Technology, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                     Words  \\\n",
       "ID                                                                                                                                                           \n",
       "0000e2070c13ff3dd2b8b8c0f4225f17  [air, air, air quality, cleantech, climate, facebook, facebook, facebook, facebook, facebook, twitter, twitter, twitter]   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                 ComputedTags  \n",
       "ID                                                                                                                                                                                                                                                                                                                                             \n",
       "0000e2070c13ff3dd2b8b8c0f4225f17  [Tag: Air, Tag: Air, Tag: Air, Tag: Pollution, Tag: Clean Technology, Tag: Climate Change, Company: Facebook, Vertical: Technology, Company: Facebook, Vertical: Technology, Company: Facebook, Vertical: Technology, Company: Facebook, Vertical: Technology, Company: Facebook, Vertical: Technology, ...  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Location: United States of America, Tag: Climate Change, Vertical: Energy & Utility, Tag: Carbon Emissions, People: Donald Trump, Application: Economy'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def list_to_csv(text):\n",
    "    str_list = \", \" . join(text)\n",
    "\n",
    "    str_list = str_list.split(\", \")\n",
    "    str_list = list(map(str.strip, str_list))\n",
    "    str_list = list(filter(None, str_list))\n",
    "    str_list = list(set(str_list))\n",
    "    str_list = \", \" . join(str_list)\n",
    "    \n",
    "    return str_list\n",
    "    \n",
    "list_to_csv(res['ComputedTags'][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "res['ComputedTags'] = res['ComputedTags'].apply(lambda x: list_to_csv(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Words</th>\n",
       "      <th>ComputedTags</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0000e2070c13ff3dd2b8b8c0f4225f17</th>\n",
       "      <td>[air, air, air quality, cleantech, climate, facebook, facebook, facebook, facebook, facebook, twitter, twitter, twitter]</td>\n",
       "      <td>Tag: Climate Change, Company: Twitter, Tag: Clean Technology, Tag: Pollution, Company: Facebook, Vertical: Technology, Tag: Air</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0007da42ffe927b4c1342461a66f9a2d</th>\n",
       "      <td>[climate, climate, climate change, economy, emissions, oil, trump, trump]</td>\n",
       "      <td>Location: United States of America, Tag: Climate Change, Vertical: Energy &amp; Utility, Tag: Carbon Emissions, People: Donald Trump, Application: Economy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0009e42a6f21891a171b30d1b415d5f4</th>\n",
       "      <td>[economic, economic, legal, meeting, start ups, switzerland, switzerland, uber]</td>\n",
       "      <td>Application: Legal, Company: Uber, Vertical: Automotive, Tag: Meetings, Application: Economy, Location: Switzerland, Tag: Startup</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>000ba56372d999c4b16ec1bd2bb13a9b</th>\n",
       "      <td>[ad, twitter]</td>\n",
       "      <td>Vertical: Technology, Company: Twitter, Vertical: Advertising</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0021a5c5b7e75c70e0ad0a0d1193a873</th>\n",
       "      <td>[ai, apps, car, car, data, ford, learning, mercedes, mercedes, nvidia, platform, safety, self driving, vehicle, vehicles]</td>\n",
       "      <td>Tag: Platform, Company: Mercedes, Vertical: Automotive, Tag: Safety, Tech: AI, Application: Autonomous Vehicles, Company: NVIDIA, Tag: Development, Tech: Mobile, Company: Ford, Vertical: Technology, Tag: Data</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                      Words  \\\n",
       "ID                                                                                                                                                            \n",
       "0000e2070c13ff3dd2b8b8c0f4225f17   [air, air, air quality, cleantech, climate, facebook, facebook, facebook, facebook, facebook, twitter, twitter, twitter]   \n",
       "0007da42ffe927b4c1342461a66f9a2d                                                  [climate, climate, climate change, economy, emissions, oil, trump, trump]   \n",
       "0009e42a6f21891a171b30d1b415d5f4                                            [economic, economic, legal, meeting, start ups, switzerland, switzerland, uber]   \n",
       "000ba56372d999c4b16ec1bd2bb13a9b                                                                                                              [ad, twitter]   \n",
       "0021a5c5b7e75c70e0ad0a0d1193a873  [ai, apps, car, car, data, ford, learning, mercedes, mercedes, nvidia, platform, safety, self driving, vehicle, vehicles]   \n",
       "\n",
       "                                                                                                                                                                                                                                      ComputedTags  \n",
       "ID                                                                                                                                                                                                                                                  \n",
       "0000e2070c13ff3dd2b8b8c0f4225f17                                                                                   Tag: Climate Change, Company: Twitter, Tag: Clean Technology, Tag: Pollution, Company: Facebook, Vertical: Technology, Tag: Air  \n",
       "0007da42ffe927b4c1342461a66f9a2d                                                            Location: United States of America, Tag: Climate Change, Vertical: Energy & Utility, Tag: Carbon Emissions, People: Donald Trump, Application: Economy  \n",
       "0009e42a6f21891a171b30d1b415d5f4                                                                                 Application: Legal, Company: Uber, Vertical: Automotive, Tag: Meetings, Application: Economy, Location: Switzerland, Tag: Startup  \n",
       "000ba56372d999c4b16ec1bd2bb13a9b                                                                                                                                                     Vertical: Technology, Company: Twitter, Vertical: Advertising  \n",
       "0021a5c5b7e75c70e0ad0a0d1193a873  Tag: Platform, Company: Mercedes, Vertical: Automotive, Tag: Safety, Tech: AI, Application: Autonomous Vehicles, Company: NVIDIA, Tag: Development, Tech: Mobile, Company: Ford, Vertical: Technology, Tag: Data  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "articoli = articoli.merge(res, on=\"ID\", how='left')\n",
    "articoli = articoli.replace(np.nan, '', regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Titolo</th>\n",
       "      <th>Data</th>\n",
       "      <th>Testo</th>\n",
       "      <th>ID</th>\n",
       "      <th>Txt</th>\n",
       "      <th>Anno</th>\n",
       "      <th>Mese</th>\n",
       "      <th>Day</th>\n",
       "      <th>Week</th>\n",
       "      <th>Keywords</th>\n",
       "      <th>Words</th>\n",
       "      <th>ComputedTags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Numenta Is Imitating Your Brain</td>\n",
       "      <td>2008-07-11</td>\n",
       "      <td>Decent piece in BusinessWeek profiling Jeff Hawkins startup Numenta. Numenta is building artificial intelligence that attempts to replicate the function of the human neocortex to solve hard problems. The software specializes in recognizing patterns within massive streams of data. I am a big fan ...</td>\n",
       "      <td>52360f85d1245da83f1da41ebc3e8449</td>\n",
       "      <td>numenta imitating brain decent piece businessweek profiling jeff hawkins startup numenta numenta building artificial intelligence attempts replicate function human neocortex solve hard problems software specializes recognizing patterns within massive streams data big fan jeff hawkins short plug ...</td>\n",
       "      <td>2008</td>\n",
       "      <td>7</td>\n",
       "      <td>11</td>\n",
       "      <td>28</td>\n",
       "      <td>jeff, brain, palm, decent, intelligence, specializes, tech industry, secrets, straightforward, inner, recognizing, introduction, pursue, replicate, fan, streams, unlock, neuroscience, dream, plug, attempts, book, degree, pilot, piece, tech, industry</td>\n",
       "      <td>[brain, neuroscience, tech, tech industry]</td>\n",
       "      <td>Tag: Neuroscience, Tech: Brain Computer Interfaces, Vertical: Health &amp; Medicine, Tag: Technology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Want to reverse engineer the brain?  Reverse engineer the roundworm first…</td>\n",
       "      <td>2008-07-16</td>\n",
       "      <td>From the IEEE report on the singularity I found an interesting piece of information from the article titled Can Can Machines Be Conscious? by Christof Koch and Giulio Tononi. It would seem mankind s attempt to reverse engineer the brain is quite a ways off if we can t even reverse engineer the 3...</td>\n",
       "      <td>d99a761a52235562022f899b002022a5</td>\n",
       "      <td>want reverse engineer brain reverse engineer roundworm ieee report singularity found interesting piece information article titled machines conscious christof koch giulio tononi seem mankind attempt reverse engineer brain quite ways reverse engineer neuron roundworm article best build conscious m...</td>\n",
       "      <td>2008</td>\n",
       "      <td>7</td>\n",
       "      <td>16</td>\n",
       "      <td>29</td>\n",
       "      <td>brain, synapses, conscious, reverse, engineer, machine, consciousness, strategies, decades, article, whose, koch, microscopy, simulating, foreseeable future, wiring, ieee, foreseeable, strengths, lesson, explicit, electron, titled, complementary, nervous, foreseeable, future</td>\n",
       "      <td>[brain, consciousness, future, ieee, simulating]</td>\n",
       "      <td>Tech: Brain Computer Interfaces, Tag: Neuroscience, Tag: Future, Tag: Simulation, Vertical: Technology, Company: IEEE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                       Titolo  \\\n",
       "0                                             Numenta Is Imitating Your Brain   \n",
       "1  Want to reverse engineer the brain?  Reverse engineer the roundworm first…   \n",
       "\n",
       "        Data  \\\n",
       "0 2008-07-11   \n",
       "1 2008-07-16   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                         Testo  \\\n",
       "0  Decent piece in BusinessWeek profiling Jeff Hawkins startup Numenta. Numenta is building artificial intelligence that attempts to replicate the function of the human neocortex to solve hard problems. The software specializes in recognizing patterns within massive streams of data. I am a big fan ...   \n",
       "1  From the IEEE report on the singularity I found an interesting piece of information from the article titled Can Can Machines Be Conscious? by Christof Koch and Giulio Tononi. It would seem mankind s attempt to reverse engineer the brain is quite a ways off if we can t even reverse engineer the 3...   \n",
       "\n",
       "                                 ID  \\\n",
       "0  52360f85d1245da83f1da41ebc3e8449   \n",
       "1  d99a761a52235562022f899b002022a5   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                           Txt  \\\n",
       "0  numenta imitating brain decent piece businessweek profiling jeff hawkins startup numenta numenta building artificial intelligence attempts replicate function human neocortex solve hard problems software specializes recognizing patterns within massive streams data big fan jeff hawkins short plug ...   \n",
       "1  want reverse engineer brain reverse engineer roundworm ieee report singularity found interesting piece information article titled machines conscious christof koch giulio tononi seem mankind attempt reverse engineer brain quite ways reverse engineer neuron roundworm article best build conscious m...   \n",
       "\n",
       "   Anno  Mese  Day Week  \\\n",
       "0  2008     7   11   28   \n",
       "1  2008     7   16   29   \n",
       "\n",
       "                                                                                                                                                                                                                                                                              Keywords  \\\n",
       "0                            jeff, brain, palm, decent, intelligence, specializes, tech industry, secrets, straightforward, inner, recognizing, introduction, pursue, replicate, fan, streams, unlock, neuroscience, dream, plug, attempts, book, degree, pilot, piece, tech, industry   \n",
       "1  brain, synapses, conscious, reverse, engineer, machine, consciousness, strategies, decades, article, whose, koch, microscopy, simulating, foreseeable future, wiring, ieee, foreseeable, strengths, lesson, explicit, electron, titled, complementary, nervous, foreseeable, future   \n",
       "\n",
       "                                              Words  \\\n",
       "0        [brain, neuroscience, tech, tech industry]   \n",
       "1  [brain, consciousness, future, ieee, simulating]   \n",
       "\n",
       "                                                                                                            ComputedTags  \n",
       "0                       Tag: Neuroscience, Tech: Brain Computer Interfaces, Vertical: Health & Medicine, Tag: Technology  \n",
       "1  Tech: Brain Computer Interfaces, Tag: Neuroscience, Tag: Future, Tag: Simulation, Vertical: Technology, Company: IEEE  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "articoli.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def count_tags(tags):\n",
    "    tag_list = tags.split(\",\")\n",
    "    \n",
    "    #deduplica\n",
    "    tag_list = list(map(str.strip, tag_list))\n",
    "    tag_list = list(filter(None, tag_list))\n",
    "    tag_list = list(set(tag_list))\n",
    "    \n",
    "    return (len(tag_list))\n",
    "    \n",
    "count_tags(articoli['ComputedTags'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "articoli['NumberOfTags'] = articoli['ComputedTags'].apply(lambda x: count_tags(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(12,6))\n",
    "ax=sns.countplot(articoli[\"NumberOfTags\"])\n",
    "plt.xlabel(\"Numero di tag per articolo\")\n",
    "plt.ylabel(\"Articoli\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "articoli senza tags: 59\n"
     ]
    }
   ],
   "source": [
    "df_zero = articoli[articoli['NumberOfTags'] == 0]\n",
    "print (\"articoli senza tags: %d\" % len(df_zero['ID']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "articoli con un solo tag: 326\n"
     ]
    }
   ],
   "source": [
    "df_uno = articoli[articoli['NumberOfTags'] == 1]\n",
    "print (\"articoli con un solo tag: %d\" % len(df_uno['ID']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_zero.to_csv('prova.csv', sep=\";\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-27LekL_lqVR"
   },
   "source": [
    "## Split tags in columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Company', 'People', 'Tech', 'Vertical', 'Tag', 'Location', 'Application']"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Extract keywords for each row\n",
    "def get_tags_types(tags):\n",
    "    tag_types = []\n",
    "    for tag in tags:\n",
    "        t1 = tag.split(\",\")[0]\n",
    "        if len(t1):\n",
    "            t2 = t1.split(\":\")[0]\n",
    "            tag_types.append(t2)\n",
    "            \n",
    "    tag_types = list(map(str.strip, tag_types))\n",
    "    tag_types = list(filter(None, tag_types))\n",
    "    tag_types = list(set(tag_types))\n",
    "    \n",
    "    return tag_types\n",
    "    \n",
    "get_tags_types(articoli['ComputedTags'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Brain Computer Interfaces'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def split_tags_in_columns(tags, column):\n",
    "    tag_list = tags.split(\",\")\n",
    "\n",
    "    tag = []\n",
    "    for t in tag_list:\n",
    "        if t.split(\":\")[0].strip() == column:\n",
    "            tag.append(t.split(\":\")[1].strip())\n",
    "            #return t.split(\":\")[1].strip()\n",
    "        \n",
    "    str_tag = \", \" . join(tag)\n",
    "    return str_tag\n",
    "    \n",
    "split_tags_in_columns(articoli['ComputedTags'][4], 'Tech')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "for tt in get_tags_types(articoli['ComputedTags']):\n",
    "    articoli[tt] = articoli['ComputedTags'].apply(lambda x: split_tags_in_columns(x, tt))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-27LekL_lqVR"
   },
   "source": [
    "## Save assets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "#with open('stop_words', 'wb') as stopwords_dump:\n",
    "#    pickle.dump(stop_words, stopwords_dump)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_filename = 'temp/db'\n",
    "articoli.to_csv(output_filename, sep=\";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-27LekL_lqVR"
   },
   "source": [
    "# Simbiosity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.dataquest.io/blog/tutorial-time-series-analysis-with-pandas/\n",
    "\n",
    "df = articoli[['Data', 'Tech']]\n",
    "df = df[~(df['Tech'].str.len() == 0)]\n",
    "#df['Data'] = pd.to_datetime(df['Data']).dt.date"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-27LekL_lqVR"
   },
   "source": [
    "### Apply Simbiosity Taxonomy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def expand_column(tags, colname):\n",
    "    if colname in tags:\n",
    "        return 1\n",
    "\n",
    "    return 0\n",
    "\n",
    "expand_column(articoli['Tech'][23], 'Artificial Intelligence')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_list = [\n",
    "    'Artificial Intelligence', 'Deep Learning', 'Machine Learning', 'Math and Statistics', 'RPA', 'Reinforced Learning',\n",
    "    'Virtual Reality', 'Augmented Reality', 'Haptics', 'Brain Computer Interfaces',\n",
    "    'IoT', 'Robotics', 'Sensors', 'Drones', 'Lidar'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in col_list:\n",
    "    df[c] = df['Tech'].apply(lambda x: expand_column(x, c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['AI'] = (df['Artificial Intelligence'] + df['Deep Learning'] \n",
    "             + df['Machine Learning'] + df['Reinforced Learning']\n",
    "             + df['Math and Statistics'] + df['RPA'])\n",
    "\n",
    "df['XR'] = (df['Virtual Reality'] + df['Augmented Reality'] + df['Haptics'] \n",
    "             + df['Brain Computer Interfaces'])\n",
    "\n",
    "df['IIoT'] = (df['IoT'] +df['Robotics'] + df['Sensors'] + df['Drones'] + df['Lidar'])\n",
    "\n",
    "df.drop(['Artificial Intelligence', 'Deep Learning', 'Machine Learning', 'Math and Statistics', 'RPA', 'Reinforced Learning',\n",
    "    'Virtual Reality', 'Augmented Reality', 'Haptics', 'Brain Computer Interfaces',\n",
    "    'IoT', 'Robotics', 'Sensors', 'Drones', 'Lidar'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#serve pure qui la explode\n",
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.set_index(df['Data'])\n",
    "#df = df.resample('M').sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Somma\"] = df[list(df)].sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['AI%'] = df['AI'] / df['Somma']\n",
    "df['XR%'] = df['XR'] / df['Somma']\n",
    "df['IIoT%'] = df['IIoT'] / df['Somma']\n",
    "df = df.replace(np.nan, 0, regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_monthly = df.resample('M').sum()\n",
    "df_yearly = df.resample('M').sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = '2019-01-01'\n",
    "#start = '2020-02-01'\n",
    "end = '2020-08-31'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-27LekL_lqVR"
   },
   "source": [
    "### Mounthly % of articles about AI overall (2020)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figure Size \n",
    "fig, ax = plt.subplots(figsize =(16, 9)) \n",
    "\n",
    "# Horizontal Bar Plot \n",
    "#df_monthly.loc['2019':'2020-08-31', 'AI%'].plot.barh()\n",
    "df_monthly.loc[start:end, 'AI%'].plot.barh()\n",
    "\n",
    "ax.set_yticklabels(df_monthly.loc[start:end, 'AI%'].index.strftime('%B %Y'))\n",
    "  \n",
    "# Remove axes splines \n",
    "for s in ['top', 'bottom', 'left', 'right']: \n",
    "    ax.spines[s].set_visible(False) \n",
    "\n",
    "# Remove x, y Ticks \n",
    "ax.xaxis.set_ticks_position('none') \n",
    "ax.yaxis.set_ticks_position('none') \n",
    "  \n",
    "# Add padding between axes and labels \n",
    "ax.xaxis.set_tick_params(pad = 5) \n",
    "ax.yaxis.set_tick_params(pad = 10) \n",
    "\n",
    "# Remove x axis value\n",
    "ax.xaxis.set_visible(False)\n",
    "  \n",
    "# Show top values  \n",
    "# ax.invert_yaxis() \n",
    "  \n",
    "# Add annotation to bars \n",
    "#for i in ax.patches:\n",
    "#    if i.get_width() > 0:\n",
    "#        plt.text(i.get_width()+0.01, i.get_y()+0.2, \"{:.2%}\".format(round(i.get_width(),3)), \n",
    "#                 fontsize = 10, fontweight ='bold', color ='grey') \n",
    "\n",
    "# Add Plot Title \n",
    "ax.set_title('Monthly % of articles about AI overall (2020)', loc ='left', ) \n",
    "  \n",
    "# Add Text watermark \n",
    "ax.text(0.9, 0.9, 'Powered by TTRADAR', \n",
    "        fontsize = 11, color ='grey', alpha = 0.7,\n",
    "        horizontalalignment='center', verticalalignment='center', \n",
    "        transform=ax.transAxes)### % of AI Articles overall\n",
    "  \n",
    "# Show Plot \n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-27LekL_lqVR"
   },
   "source": [
    "### Yearly articles about selected technologies (2014 - 2020)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figure Size \n",
    "fig, ax = plt.subplots(figsize =(16, 9)) \n",
    "\n",
    "x = df_yearly.index\n",
    "y1 = df_yearly['AI']\n",
    "y2 = df_yearly['XR']\n",
    "y3 = df_yearly['IIoT']\n",
    "\n",
    "plt.plot(x,y1,marker='.', label=\"Artificial Intelligence\")\n",
    "plt.plot(x,y2,marker='.', label='Extended Reality')\n",
    "plt.plot(x,y3,marker='.', label='Industrial IoT')\n",
    "\n",
    "# Add Plot Title \n",
    "ax.set_title('Yearly articles about selected technologies (2014 - 2020)', loc ='left', ) \n",
    "  \n",
    "# Add Text watermark \n",
    "ax.text(0.9, 0.05, 'Powered by TTRADAR', \n",
    "        fontsize = 11, color ='grey', alpha = 0.7,\n",
    "        horizontalalignment='center', verticalalignment='center', \n",
    "        transform=ax.transAxes)\n",
    "\n",
    "#plt.legend()\n",
    "\n",
    "# Show Plot \n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_x = df_monthly.loc[start:end]\n",
    "\n",
    "# Figure Size \n",
    "fig, ax = plt.subplots(figsize =(16, 9)) \n",
    "\n",
    "df_x['AI'].plot(marker='.', alpha=0.5, linestyle='-', subplots=False)\n",
    "df_x['XR'].plot(marker='.', alpha=0.5, linestyle='-', subplots=False)\n",
    "df_x['IIoT'].plot(marker='.', alpha=0.5, linestyle='-', subplots=False)\n",
    "\n",
    "# Remove x, y Ticks \n",
    "ax.xaxis.set_ticks_position('none') \n",
    "ax.yaxis.set_ticks_position('none') \n",
    "    \n",
    "# Add padding between axes and labels \n",
    "ax.xaxis.set_tick_params(pad = 5) \n",
    "ax.yaxis.set_tick_params(pad = 10) \n",
    "\n",
    "# Remove y axis value\n",
    "ax.yaxis.set_visible(False)\n",
    "\n",
    "#plt.legend()\n",
    "\n",
    "# Add Plot Title \n",
    "ax.set_title('Mounthly articles about selected technologies (2020)', loc ='left', ) \n",
    "  \n",
    "# Add Text watermark \n",
    "ax.text(0.9, 0.05, 'Powered by TTRADAR', \n",
    "        fontsize = 11, color ='grey', alpha = 0.7,\n",
    "        horizontalalignment='center', verticalalignment='center', \n",
    "        transform=ax.transAxes)\n",
    "\n",
    "# Show Plot \n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-27LekL_lqVR"
   },
   "source": [
    "### Tech + Application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tech_appl = articoli[['Data', 'Tech', 'Application']]\n",
    "tech_appl = tech_appl[~(tech_appl['Tech'].str.len() == 0)]\n",
    "tech_appl = tech_appl[~(tech_appl['Application'].str.len() == 0)]\n",
    "tech_appl = tech_appl.set_index(tech_appl['Data'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "tech_appl.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def explode(df):\n",
    "    data_tech = pd.concat([pd.Series(row['Data'], row['Tech'].split(', '))              \n",
    "           for _, row in df.iterrows()])\n",
    "    df1 = pd.DataFrame({'Data':data_tech.values, 'Tech':data_tech.index})\n",
    "\n",
    "    data_appl = pd.concat([pd.Series(row['Data'], row['Application'].split(', '))              \n",
    "           for _, row in df.iterrows()])\n",
    "\n",
    "    df2 = pd.DataFrame({'Data':data_appl.values, 'Application':data_appl.index})\n",
    "\n",
    "    res = pd.merge(df1,df2,on='Data',how='left')\n",
    "    res = res.sort_index()\n",
    "    res = res.reset_index(drop=True)\n",
    "    \n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tech_appl = explode(tech_appl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tech_appl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-27LekL_lqVR"
   },
   "source": [
    "### Top Applications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_series = tech_appl.groupby(['Application']).size()\n",
    "applications = count_series.to_frame(name = 'Size').reset_index()\n",
    "applications = applications[applications.Size > 100]\n",
    "applications.sort_values(by = 'Size', ascending=False, inplace=True)\n",
    "applications.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,6))\n",
    "ax=sns.barplot(x='Application', y='Size', data=applications)\n",
    "\n",
    "ax.set_xticklabels(ax.get_xticklabels(), rotation=45, horizontalalignment='right')\n",
    "plt.ylabel(\"Articoli\")\n",
    "plt.xlabel(\"Applicazione\")\n",
    "\n",
    "\n",
    "# Remove x, y Ticks \n",
    "ax.xaxis.set_ticks_position('none') \n",
    "ax.yaxis.set_ticks_position('none') \n",
    "\n",
    "ax.set_ylabel('')    \n",
    "ax.set_xlabel('')\n",
    "\n",
    "# Remove y axis value\n",
    "ax.yaxis.set_visible(False)\n",
    "\n",
    "# Add Plot Title \n",
    "ax.set_title('Top applications', loc ='left') \n",
    "\n",
    "ax.text(0.9, 0.9, 'Powered by TTRADAR', \n",
    "        fontsize = 11, color ='grey', alpha = 0.7,\n",
    "        horizontalalignment='center', verticalalignment='center', \n",
    "        transform=ax.transAxes)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-27LekL_lqVR"
   },
   "source": [
    "### Tech = Artificial Intelligence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_AI = tech_appl.loc[tech_appl['Tech'] == \"Artificial Intelligence\"]\n",
    "count_series = df_AI.groupby(['Tech', 'Application']).size()\n",
    "\n",
    "df_AI = count_series.to_frame(name = 'Size').reset_index()\n",
    "df_AI = df_AI[df_AI.Size > 40]\n",
    "df_AI.sort_values(by = 'Size', ascending=False, inplace=True)\n",
    "df_AI.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,6))\n",
    "ax=sns.barplot(x='Application', y='Size', data=df_AI)\n",
    "\n",
    "ax.set_xticklabels(ax.get_xticklabels(), rotation=45, horizontalalignment='right')\n",
    "plt.ylabel(\"Articoli\")\n",
    "plt.xlabel(\"Applicazione\")\n",
    "\n",
    "# Remove x, y Ticks \n",
    "ax.xaxis.set_ticks_position('none') \n",
    "ax.yaxis.set_ticks_position('none') \n",
    "\n",
    "ax.set_ylabel('')    \n",
    "ax.set_xlabel('')\n",
    "\n",
    "# Remove y axis value\n",
    "#ax.yaxis.set_visible(False)\n",
    "\n",
    "# Add Plot Title \n",
    "ax.set_title('Top Applications for Artificial Intelligence', loc ='left') \n",
    "\n",
    "ax.text(0.9, 0.9, 'Powered by TTRADAR', \n",
    "        fontsize = 11, color ='grey', alpha = 0.7,\n",
    "        horizontalalignment='center', verticalalignment='center', \n",
    "        transform=ax.transAxes)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-27LekL_lqVR"
   },
   "source": [
    "### Application = Autonomous Vehicles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_AutonomousVehicles = tech_appl.loc[tech_appl['Application'] == \"Autonomous Vehicles\"]\n",
    "count_series = df_AutonomousVehicles.groupby(['Tech', 'Application']).size()\n",
    "\n",
    "df_AutonomousVehicles = count_series.to_frame(name = 'Size').reset_index()\n",
    "df_AutonomousVehicles = df_AutonomousVehicles[df_AutonomousVehicles.Size < 100]\n",
    "df_AutonomousVehicles = df_AutonomousVehicles[df_AutonomousVehicles.Size > 10]\n",
    "df_AutonomousVehicles.sort_values(by = 'Size', ascending=False, inplace=True)\n",
    "df_AutonomousVehicles.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,6))\n",
    "ax=sns.barplot(x='Tech', y='Size', data=df_AutonomousVehicles)\n",
    "\n",
    "ax.set_xticklabels(ax.get_xticklabels(), rotation=45, horizontalalignment='right')\n",
    "plt.ylabel(\"Articoli\")\n",
    "plt.xlabel(\"Applicazione\")\n",
    "\n",
    "# Remove x, y Ticks \n",
    "ax.xaxis.set_ticks_position('none') \n",
    "ax.yaxis.set_ticks_position('none') \n",
    "\n",
    "ax.set_ylabel('')    \n",
    "ax.set_xlabel('')\n",
    "\n",
    "# Remove y axis value\n",
    "#ax.yaxis.set_visible(False)\n",
    "\n",
    "# Add Plot Title \n",
    "ax.set_title('Technologies for Autonomous Vehicles applications', loc ='left') \n",
    "\n",
    "ax.text(0.9, 0.9, 'Powered by TTRADAR', \n",
    "        fontsize = 11, color ='grey', alpha = 0.7,\n",
    "        horizontalalignment='center', verticalalignment='center', \n",
    "        transform=ax.transAxes)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-27LekL_lqVR"
   },
   "source": [
    "### Application = Energy Storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_energystorage = tech_appl.loc[tech_appl['Application'] == \"Energy Storage\"]\n",
    "count_series = df_energystorage.groupby(['Tech', 'Application']).size()\n",
    "\n",
    "df_energystorage = count_series.to_frame(name = 'Size').reset_index()\n",
    "df_energystorage = df_energystorage[df_energystorage.Size > 10]\n",
    "df_energystorage.sort_values(by = 'Size', ascending=False, inplace=True)\n",
    "df_energystorage.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,6))\n",
    "ax=sns.barplot(x='Tech', y='Size', data=df_energystorage)\n",
    "\n",
    "ax.set_xticklabels(ax.get_xticklabels(), rotation=0, horizontalalignment='center')\n",
    "plt.ylabel(\"Articoli\")\n",
    "plt.xlabel(\"Tecnologia\")\n",
    "\n",
    "# Remove x, y Ticks \n",
    "ax.xaxis.set_ticks_position('none') \n",
    "ax.yaxis.set_ticks_position('none') \n",
    "\n",
    "ax.set_ylabel('')    \n",
    "ax.set_xlabel('')\n",
    "\n",
    "# Remove y axis value\n",
    "ax.yaxis.set_visible(False)\n",
    "\n",
    "# Add Plot Title \n",
    "ax.set_title('Technologies for Energy Storage applications', loc ='left') \n",
    "\n",
    "# Add Text watermark \n",
    "ax.text(0.9, 0.9, 'Powered by TTRADAR', \n",
    "        fontsize = 11, color ='grey', alpha = 0.7,\n",
    "        horizontalalignment='center', verticalalignment='center', \n",
    "        transform=ax.transAxes)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = articoli[['Data', 'Tech', 'Application']]\n",
    "df = df[~(df['Tech'].str.len() == 0)]\n",
    "df = df[~(df['Application'].str.len() == 0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def explode(df):\n",
    "    data_tech = pd.concat([pd.Series(row['Data'], row['Tech'].split(', '))              \n",
    "           for _, row in df.iterrows()])\n",
    "    df1 = pd.DataFrame({'Data':data_tech.values, 'Tech':data_tech.index})\n",
    "\n",
    "    data_appl = pd.concat([pd.Series(row['Data'], row['Application'].split(', '))              \n",
    "           for _, row in df.iterrows()])\n",
    "\n",
    "    df2 = pd.DataFrame({'Data':data_appl.values, 'Application':data_appl.index})\n",
    "\n",
    "    res = pd.merge(df1,df2,on='Data',how='left')\n",
    "    res = res.sort_index()\n",
    "    res = res.reset_index(drop=True)\n",
    "    \n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = explode(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Application'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in df['Application'].unique():\n",
    "    df[c] = df['Application'].apply(lambda x: expand_column(x, c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.set_index(df['Data'])\n",
    "df = df.resample('M').sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figure Size \n",
    "fig, ax = plt.subplots(figsize =(16, 9)) \n",
    "\n",
    "x = df.loc[start:end].index\n",
    "y1 = df.loc[start:end, 'Energy Storage']\n",
    "y2 = df.loc[start:end, 'Power Generation']\n",
    "y3 = df.loc[start:end, 'Water Processing']\n",
    "y4 = df.loc[start:end, 'Recharge Infrastructure']\n",
    "\n",
    "plt.plot(x,y1,marker='.', label=\"Energy Storage\")\n",
    "plt.plot(x,y2,marker='.', label='Power Generation')\n",
    "plt.plot(x,y3,marker='.', label='Water Processing')\n",
    "plt.plot(x,y4,marker='.', label='Recharge Infrastructure')\n",
    "\n",
    "# Add Plot Title \n",
    "ax.set_title('Yearly articles about energy related applications (2014 - 2020)', loc ='left', ) \n",
    "  \n",
    "# Add Text watermark \n",
    "ax.text(0.9, 0.05, 'Powered by TTRADAR', \n",
    "        fontsize = 11, color ='grey', alpha = 0.7,\n",
    "        horizontalalignment='center', verticalalignment='center', \n",
    "        transform=ax.transAxes)\n",
    "\n",
    "plt.legend()\n",
    "\n",
    "# Show Plot \n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
